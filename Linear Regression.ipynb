{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "***\n",
    "\n",
    "<br><h2>Session 3b | Linear Regression</h2>\n",
    "<h4>DAT-5303 | Machine Learning</h4>\n",
    "Chase Kusterer - Faculty of Analytics<br>\n",
    "Hult International Business School<br><br><br>\n",
    "\n",
    "***\n",
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "<h3>Basic Course Modeling Strategy for CONTINUOUS Response Variable:</h3><br>\n",
    "\n",
    "\n",
    "<strong>Prepare for Model Development</strong><br>\n",
    "Split dataset into training and testing sets<br><br>\n",
    "\n",
    "<strong>Model Development in statsmodels</strong><br>\n",
    "Experiment with different variable combinations in linear regression (OLS) and analyze results<br><br>\n",
    "\n",
    "<strong>Develop Candidate Models</strong><br>\n",
    "Take model(s) with highest predictive power and save its variables as a new dataset<br><br>\n",
    "\n",
    "<strong>Prepare for Model Development on New Dataset</strong><br>\n",
    "Split new dataset into training and testing sets<br><br>\n",
    "\n",
    "<strong>Model Tournament</strong><br>\n",
    "Experiment with different (regression) model types in scikit-learn<br><br><br>\n",
    "\n",
    "The <strong>MUST KNOW</strong> workflow of scikit-learn:\n",
    "* Instantiate\n",
    "* Fit\n",
    "* Predict\n",
    "* Score\n",
    "\n",
    "<br>\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<h3>Part I: Training and Testing Sets</h3><br>\n",
    "Our previous model building endeavors using statsmodels had one major drawback:<br><br>\n",
    "\n",
    "<div align=\"center\"><h4>The models were trained using all of the data.</h4></div><br>\n",
    "\n",
    "This may not seem like a big deal, but modeling in this way can be very dangerous. Allowing an algorithm to see all of the data runs the risk of <strong>overfitting</strong>, or tailoring so closely to a dataset that the algorithm predicts poorly on new observations. Remember, the primary goal of building a machine learning algorithm is to predict well on observations where the end result is unknown (i.e. new cases). Therefore, we need to set aside a portion of our data before training our model (known as a <strong>testing</strong> or <strong>validation set</strong>). After training, we can use this set to see how our algorithm performs on new data.<br><br>\n",
    "<strong>Some Things to Keep in Mind</strong><br>\n",
    "1. Data exploration and feature engineering are always conducted on the full dataset. There is no need to partition the data in this stage as the goal is to develop a solid understanding as to what the numbers are telling us.\n",
    "2. Never make model adjustments on the testing set. This is a very common mistake that students make. You should only make model adjustments on the training set. Otherwise, you are inviting in the very problems that you are trying to avoid with overfitting.<br><br>\n",
    "\n",
    "<strong>Challenge 1</strong><br>\n",
    "Import the following packages:\n",
    "* pandas (as pd)\n",
    "* matplotlib.pyplot (as plt)\n",
    "* seaborn (as sns)\n",
    "* statsmodels.formula.api (as smf)\n",
    "* train_test_split (from sklearn.model_selection)\n",
    "* LinearRegression (from sklearn.linear_model)\n",
    "\n",
    "\n",
    "Then, load the 'housing_feature_rich.xlsx' dataset into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd # data science essentials\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # enhanced data visualization\n",
    "import statsmodels.formula.api as smf # regression modeling\n",
    "from sklearn.model_selection import train_test_split # train/test split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "# specifying file name\n",
    "file = 'housing_feature_rich.xlsx'\n",
    "\n",
    "\n",
    "# reading the file into Python\n",
    "housing = pd.read_excel(file)\n",
    "\n",
    "\n",
    "# checking the file\n",
    "housing.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Challenge 2</strong><br>\n",
    "\n",
    "1. Prepare the explanatory variable data by dropping <strong>'SalePrice'</strong>, <strong>'out_Sale_Price'</strong>, and <strong>'Order'</strong> from the dataset (save as <strong>housing_data</strong>)\n",
    "2. Prepare the response variable data by subsetting <strong>'SalePrice'</strong> (save as <strong>housing_target</strong>)\n",
    "3. Observe the rest of the code to see how training and testing sets are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# preparing explanatory variable data\n",
    "housing_data   = housing.drop(['SalePrice',\n",
    "                               'out_Sale_Price',\n",
    "                               'Order'],\n",
    "                                axis = 1)\n",
    "\n",
    "\n",
    "# preparing response variable data\n",
    "housing_target = housing.loc[:, 'SalePrice']\n",
    "\n",
    "\n",
    "# preparing training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            housing_data,\n",
    "            housing_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)\n",
    "\n",
    "\n",
    "# Training set \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# Testing set\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<h3>Part II: Ordinary Least Squares Regression</h3><br>\n",
    "In order to work with statsmodels, we need to concatenate our training data on the 'x' side (X_train) and our training data on the 'y' side (y_train). Then, we can begin building models and analyze their results. Let's test our best model from our previous session to see how it performs. In the interest of time, this has already been prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# declaring set of x-variables\n",
    "x_variables = ['Overall Qual', 'change_sec_floor', 'NridgHt', 'Garage Cars',\n",
    "               'change_kitchen', 'out_ff_SF', 'NoRidge', 'StoneBr',\n",
    "               'Lot Area', 'change_ff_sf', 'Somerst', 'Porch Area',\n",
    "               'OldTown', 'Overall Cond', 'CollgCr', 'Fireplaces',\n",
    "               'change_garage_cars', 'change_garage_area', 'Total Bsmt SF',\n",
    "               '2nd Flr SF', 'out_Total_Bsmt_SF', 'Crawfor', 'Timber',\n",
    "               'GrnHill', 'out_Fireplaces', 'out_Porch_Area',\n",
    "               'change_porch_area', 'CulDSac', 'Gilbert', 'out_Gr_Liv_Area',\n",
    "               'IDOTRR', 'Mas Vnr Area', 'SawyerW', 'change_mas_vnr',\n",
    "               'Inside', 'Garage Area', 'Blmngtn', 'out_TotRms_AbvGrd',\n",
    "               '1st Flr SF']\n",
    "\n",
    "\n",
    "# looping to make x-variables suitable for statsmodels\n",
    "for val in x_variables:\n",
    "    print(f\"housing_train['{val}'] +\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# merging X_train and y_train so that they can be used in statsmodels\n",
    "housing_train = pd.concat([X_train, y_train], axis = 1)\n",
    "\n",
    "\n",
    "# Step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"SalePrice ~housing_train['Overall Qual'] +\n",
    "                                housing_train['change_sec_floor'] +\n",
    "                                housing_train['NridgHt'] +\n",
    "                                housing_train['Garage Cars'] +\n",
    "                                housing_train['change_kitchen'] +\n",
    "                                housing_train['out_ff_SF'] +\n",
    "                                housing_train['NoRidge'] +\n",
    "                                housing_train['StoneBr'] +\n",
    "                                housing_train['Lot Area'] +\n",
    "                                housing_train['change_ff_sf'] +\n",
    "                                housing_train['Somerst'] +\n",
    "                                housing_train['Porch Area'] +\n",
    "                                housing_train['OldTown'] +\n",
    "                                housing_train['Overall Cond'] +\n",
    "                                housing_train['CollgCr'] +\n",
    "                                housing_train['Fireplaces'] +\n",
    "                                housing_train['change_garage_cars'] +\n",
    "                                housing_train['change_garage_area'] +\n",
    "                                housing_train['Total Bsmt SF'] +\n",
    "                                housing_train['2nd Flr SF'] +\n",
    "                                housing_train['out_Total_Bsmt_SF'] +\n",
    "                                housing_train['Crawfor'] +\n",
    "                                housing_train['Timber'] +\n",
    "                                housing_train['GrnHill'] +\n",
    "                                housing_train['out_Fireplaces'] +\n",
    "                                housing_train['out_Porch_Area'] +\n",
    "                                housing_train['change_porch_area'] +\n",
    "                                housing_train['CulDSac'] +\n",
    "                                housing_train['Gilbert'] +\n",
    "                                housing_train['out_Gr_Liv_Area'] +\n",
    "                                housing_train['IDOTRR'] +\n",
    "                                housing_train['Mas Vnr Area'] +\n",
    "                                housing_train['SawyerW'] +\n",
    "                                housing_train['change_mas_vnr'] +\n",
    "                                housing_train['Inside'] +\n",
    "                                housing_train['Garage Area'] +\n",
    "                                housing_train['Blmngtn'] +\n",
    "                                housing_train['out_TotRms_AbvGrd'] +\n",
    "                                housing_train['1st Flr SF']\"\"\",\n",
    "                                data = housing_train)\n",
    "\n",
    "\n",
    "# Step 2: fit the model based on the data\n",
    "results = lm_best.fit()\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: analyze the summary output\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "Now that we have selected our x-variables, our next step is to prepare them in scikit-learn so that we can see how they predict on new data.<br><br>\n",
    "<strong>Challenge 3 - Step 1</strong><br>\n",
    "Apply the above regression model in scikit-learn:\n",
    "\n",
    "1. Set <strong>housing_data</strong> to the <strong>x_variables</strong> list\n",
    "2. Set <strong>housing_target</strong> to <strong>SalePrice</strong> \n",
    "3. Run <strong>train_test_split</strong> with a <strong>test_size</strong> of 0.25 and a <strong>random_state</strong> of 219."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# applying model in scikit-learn\n",
    "\n",
    "# Preparing a DataFrame based the the analysis above\n",
    "housing_data   = housing.loc[ : , x_variables]\n",
    "\n",
    "\n",
    "# Preparing the target variable\n",
    "housing_target = housing.loc[:, 'SalePrice']\n",
    "\n",
    "\n",
    "# running train/test split again\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            housing_data,\n",
    "            housing_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "Now that we have selected our x-variables, our next step is to prepare them in scikit-learn so that we can see how they predict on new data.<br><br>\n",
    "<strong>Challenge 3 - Step 2</strong><br>\n",
    "\n",
    "4. INSTANTIATE a <strong>LinearRegression( )</strong> object\n",
    "5. FIT the training data to the model object\n",
    "6. PREDICT using the testing data\n",
    "7. SCORE your results, rounding to four decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a model object\n",
    "lr = LinearRegression()\n",
    "\n",
    "\n",
    "# FITTING to the training data\n",
    "lr_fit = lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "lr_pred = lr_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training Score:', lr.score(X_train, y_train).round(4))\n",
    "print('Testing Score:',  lr.score(X_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lr_train_score = lr.score(X_train, y_train).round(4)\n",
    "lr_test_score  = lr.score(X_test, y_test).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>How fit should a model be?</strong><br>\n",
    "As a general heuristic, if the training and testing scores are within 0.05 of each other, the model has not been overfit. Don't worry if the testing score ends up higher than the training score. Some sources claim that in such situations, a model is underfit. However, this is rarely the case. As long as the training and testing scores are within 0.05 of each other, the model is good to go.<br><br>\n",
    "<h3>Part III: Advantages of statsmodels and scikit-learn</h3><br>\n",
    "It may seem counterproductive to build models in both statsmodels and scikit-learn, but each package has its advantages.<br><br>\n",
    "<u>Advantages of statsmodels</u><br>\n",
    "\n",
    "* This is currently the best package in Python for generating model summaries, giving modelers the advantage of being able to analyze familiar metrics such as p-values, degrees of freedom, R-Square, AIC, and BIC\n",
    "* Summary output is very similar to that of R and Excel\n",
    "<br><br>\n",
    "\n",
    "<u>Advantages of scikit-learn</u><br>\n",
    "\n",
    "* Minimal things happen behind the scenes, making scikit-learn faster than statsmodels. This becomes a serious advantage when hosting a model on a server or cloud to predict in real time\n",
    "* It is incredibly easy to change model types, allowing modelers to test several different model types with minimal effort\n",
    "<br><br>\n",
    "\n",
    "<u>Disadvantages of statsmodels</u><br>\n",
    "\n",
    "* Oftentimes, a substantial amount of code needs to be changed in order to develop models of different types\n",
    "* Much of the summary output may not be relevant to the modeling task at hand, potentially slowing practicioners down\n",
    "<br><br>\n",
    "\n",
    "<u>Disadvantages of scikit-learn</u><br>\n",
    "\n",
    "* Concepts such as p-values do not exist. Therefore, it can be tedious to properly adjust models in this package\n",
    "\n",
    "<br>\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "<br><strong>Challenge 4</strong><br>\n",
    "Instantiate, fit, predict, and score a ridge regression model ( <strong>sklearn.linear_model.Ridge( ) </strong>) using the same data as before. Note that the following import is required to complete the remainder of this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model # linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br><strong>Challenge 5</strong><br>\n",
    "Instantiate, fit, predict, and score a lasso regression model ( <strong>sklearn.linear_model.Lasso( )</strong> ) using the same data as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a model object\n",
    "lasso_model = sklearn.linear_model.Lasso()\n",
    "\n",
    "# FITTING the training data\n",
    "lasso_fit = lasso_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "lasso_pred = lasso_model.predict(X_test)\n",
    "\n",
    "print('Training Score:', lasso_model.score(X_train, y_train).round(4))\n",
    "print('Testing Score:',  lasso_model.score(X_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lasso_train_score = lasso_model.score(X_train, y_train).round(4)\n",
    "lasso_test_score  = lasso_model.score(X_test, y_test).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br><strong>Challenge 6</strong><br>\n",
    "Instantiate, fit, predict, and score a Bayesian ARD regression model ( <strong>sklearn.linear_model.ARDRegression()</strong> ) using the same data as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a model object\n",
    "ard_model = sklearn.linear_model.ARDRegression()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "ard_fit = ard_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "ard_pred = ard_model.predict(X_test)\n",
    "\n",
    "\n",
    "print('Training Score:', ard_model.score(X_train, y_train).round(4))\n",
    "print('Testing Score:',  ard_model.score(X_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "ard_train_score = ard_model.score(X_train, y_train).round(4)\n",
    "ard_test_score  = ard_model.score(X_test, y_test).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Comparing Results</strong><br>\n",
    "Let's compare the results of each model. In the interest of time, this code has already been written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# comparing results\n",
    "\n",
    "print(f\"\"\"\n",
    "Model      Train Score      Test Score\n",
    "-----      -----------      ----------\n",
    "OLS        {lr_train_score}           {lr_test_score}\n",
    "Ridge      {ridge_train_score}           {ridge_test_score}\n",
    "Lasso      {lasso_train_score}           {lasso_test_score}\n",
    "ARD        {ard_train_score}           {ard_test_score}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {'Model'    : ['OLS', 'Ridge', 'Lasso', 'ARD'],\n",
    "           \n",
    "                     'Training' : [lr_train_score, ridge_train_score,\n",
    "                                   lasso_train_score, ard_train_score],\n",
    "           \n",
    "                     'Testing'  : [lr_test_score, ridge_test_score,\n",
    "                                   lasso_test_score, ard_test_score]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)\n",
    "\n",
    "\n",
    "# sending model results to Excel\n",
    "model_performance.to_excel('regression_model_performance.xlsx',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "<h3>Part IV: Model Predictions and Residuals</h3><br>\n",
    "After choosing a final model, it is important to check its residuals to ensure prediction errors are even across the modeling space. If the residuals appear to have no pattern, your model is in good shape. If they appear to be fanning in or fanning out, there may be more undiscovered features to engineer in order to capture more predictive value, or there may be nonlinear relationships present.<br><br>\n",
    "<strong>Challenge 7</strong><br>\n",
    "Take your favorite model from above. Plug in its prediction values into the residual plot below. Prediction values have been saved as objects under the following naming convention:\n",
    "\n",
    "~~~\n",
    "MODEL_pred\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# setting figure size\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "\n",
    "\n",
    "# developing a residual plot\n",
    "sns.residplot(x = ard_pred,\n",
    "              y = y_test)\n",
    "\n",
    "\n",
    "# saving figure in working directory\n",
    "plt.savefig(\"Housing Residual Plot.png\")\n",
    "\n",
    "\n",
    "# displaying the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}